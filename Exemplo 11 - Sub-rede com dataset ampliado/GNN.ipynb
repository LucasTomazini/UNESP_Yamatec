{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/tfjonas/ggnn_fault_loc/blob/master/ggnn_fault_loc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "hCd8cKycsjHm",
    "outputId": "63e9447a-2d09-46e0-962e-99a4d5436dd6"
   },
   "outputs": [],
   "source": [
    "#!git clone https://$GITHUB_AUTH@github.com/tfjonas/ggnn_fault_loc.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "9jJ2dH996c0t",
    "outputId": "0e6d53ca-3a5f-43fa-efec-b392676d08b2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'dataset/'\n",
    "TrainDataset = torch.load(folder + 'train_dataset_d11_nz.pt')\n",
    "TestDataset = torch.load(folder + 'test_dataset_d11_nz.pt')\n",
    "#UnrelatedDataset = torch.load('unrelated_dataset_rev6.pt')\n",
    "\n",
    "adj_matrices = torch.load(folder + 'adj_matrices_d11_nz.pt')\n",
    "dist_matrices = torch.load(folder + 'dist_matrices_d11_nz.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import GGNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUTS = 1\n",
    "PROPAG_STEPS = 15\n",
    "HIDDEN_LAYER = 128\n",
    "model = GGNN.GGNNModel(INPUTS, HIDDEN_LAYER, PROPAG_STEPS).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 15\n",
    "\n",
    "trainLoader = torch.utils.data.DataLoader(TrainDataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "TestLoader = torch.utils.data.DataLoader(TestDataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "classes = (0,1,2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "criterion_1 = nn.NLLLoss()\n",
    "criterion_2 = nn.CrossEntropyLoss()\n",
    "criterion_3 = nn.PoissonNLLLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STEPS_PER_EPOCH = int((len(TrainDataset)/BATCH_SIZE) * 3)\n",
    "STEPS_PER_EPOCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.6964],\n",
       "         [0.6964],\n",
       "         [0.2992],\n",
       "         [0.8232],\n",
       "         [0.5345],\n",
       "         [0.5824],\n",
       "         [0.4138],\n",
       "         [0.4377]], dtype=torch.float64),\n",
       " tensor(2),\n",
       " tensor(1))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainDataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH:  1\n",
      "--- 0.0 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  2\n",
      "--- 0.1 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  3\n",
      "--- 0.1 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  4\n",
      "--- 0.1 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  5\n",
      "--- 0.2 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  6\n",
      "--- 0.2 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  7\n",
      "--- 0.2 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  8\n",
      "--- 0.3 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  9\n",
      "--- 0.3 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  10\n",
      "--- 0.3 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  11\n",
      "--- 0.3 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  12\n",
      "--- 0.4 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  13\n",
      "--- 0.4 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  14\n",
      "--- 0.4 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  15\n",
      "--- 0.5 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  16\n",
      "--- 0.5 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  17\n",
      "--- 0.5 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  18\n",
      "--- 0.6 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  19\n",
      "--- 0.6 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  20\n",
      "--- 0.6 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  21\n",
      "--- 0.7 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  22\n",
      "--- 0.7 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  23\n",
      "--- 0.7 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  24\n",
      "--- 0.8 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  25\n",
      "--- 0.8 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  26\n",
      "--- 0.8 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  27\n",
      "--- 0.8 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  28\n",
      "--- 0.9 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  29\n",
      "--- 0.9 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  30\n",
      "--- 0.9 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  31\n",
      "--- 1.0 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  32\n",
      "--- 1.0 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  33\n",
      "--- 1.0 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  34\n",
      "--- 1.1 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  35\n",
      "--- 1.1 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  36\n",
      "--- 1.1 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  37\n",
      "--- 1.2 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  38\n",
      "--- 1.2 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  39\n",
      "--- 1.2 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  40\n",
      "--- 1.3 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  41\n",
      "--- 1.3 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  42\n",
      "--- 1.3 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  43\n",
      "--- 1.4 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  44\n",
      "--- 1.4 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  45\n",
      "--- 1.4 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  46\n",
      "--- 1.4 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  47\n",
      "--- 1.5 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  48\n",
      "--- 1.5 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  49\n",
      "--- 1.5 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  50\n",
      "--- 1.6 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  51\n",
      "--- 1.6 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  52\n",
      "--- 1.6 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  53\n",
      "--- 1.7 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  54\n",
      "--- 1.7 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  55\n",
      "--- 1.7 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  56\n",
      "--- 1.8 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  57\n",
      "--- 1.8 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  58\n",
      "--- 1.8 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  59\n",
      "--- 1.9 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  60\n",
      "--- 1.9 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  61\n",
      "--- 1.9 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  62\n",
      "--- 2.0 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  63\n",
      "--- 2.0 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  64\n",
      "--- 2.0 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  65\n",
      "--- 2.0 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  66\n",
      "--- 2.1 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  67\n",
      "--- 2.1 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  68\n",
      "--- 2.1 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  69\n",
      "--- 2.2 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  70\n",
      "--- 2.2 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  71\n",
      "--- 2.2 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  72\n",
      "--- 2.3 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  73\n",
      "--- 2.3 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  74\n",
      "--- 2.3 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  75\n",
      "--- 2.4 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  76\n",
      "--- 2.4 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  77\n",
      "--- 2.4 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  78\n",
      "--- 2.5 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  79\n",
      "--- 2.5 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  80\n",
      "--- 2.5 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  81\n",
      "--- 2.6 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  82\n",
      "--- 2.6 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  83\n",
      "--- 2.6 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  84\n",
      "--- 2.7 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  85\n",
      "--- 2.7 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  86\n",
      "--- 2.7 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  87\n",
      "--- 2.8 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  88\n",
      "--- 2.8 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  89\n",
      "--- 2.8 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  90\n",
      "--- 2.9 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  91\n",
      "--- 2.9 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  92\n",
      "--- 2.9 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  93\n",
      "--- 2.9 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  94\n",
      "--- 3.0 mins ---\n",
      "\n",
      "\n",
      "EPOCH:  95\n",
      "--- 3.0 mins ---\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start_time = time.time()\n",
    "\n",
    "EPOCHS = 100\n",
    "epoch_loss = []\n",
    "loss_ls = []\n",
    "predict = []\n",
    "acc = []\n",
    "lss = []\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    acc_ep = []\n",
    "    loss_ep = []\n",
    "    for step in range(STEPS_PER_EPOCH):\n",
    "        # Get batch data\n",
    "        X, T, idx = next(iter(trainLoader))\n",
    "        A = adj_matrices[idx]\n",
    "        # Forward pass: Compute predicted y by passing x to the model\n",
    "        Y = model(X.cuda(), A.cuda())\n",
    "        # Compute loss\n",
    "        loss = criterion_2(Y, T.cuda())\n",
    "\n",
    "        predictions = torch.exp(Y).argmax(-1)\n",
    "        #print('EPOCH: ', epoch)\n",
    "        #print('Y', predictions)       \n",
    "        #print('T', T)\n",
    "        #print('Loss', loss)\n",
    "        #print('\\n')\n",
    "\n",
    "        aux = 0\n",
    "        for j in range(len(T)):\n",
    "\n",
    "            if T[j].item() == predictions[j].item():\n",
    "                aux += 1\n",
    "\n",
    "        #print('Acc:', aux/len(T))\n",
    "\n",
    "        acc_ep.append(aux/len(T))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss.append(loss.item())\n",
    "        loss_ls.append(loss.item())\n",
    "\n",
    "        loss_ep.append(loss.item())\n",
    "\n",
    "        predict.append(torch.exp(Y).argmax(-1))\n",
    "    acc.append(np.array(acc_ep).mean())\n",
    "    lss.append(np.array(loss_ep).mean())\n",
    "    statistics = {'loss_ls': loss_ls, 'accuracy': acc}\n",
    "    print('EPOCH: ', epoch+1)\n",
    "    print(\"--- %s mins ---\" % round(((time.time() - start_time)/60),1))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'acc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-d1796c09fdfa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0macc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'b'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;31m#plt.plot(lss, color='r', label='Loss')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m#plt.plot(acc_t, color='r', label='Test')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'acc' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "name = 'PROPAG_STEPS: {}, HIDDEN_LAYER: {}, BATCH_SIZE: {}, EPOCHS: {}'\n",
    "\n",
    "\n",
    "plt.subplots(figsize=(15, 10))\n",
    "plt.plot(acc, color='b', label='Train')\n",
    "#plt.plot(lss, color='r', label='Loss')\n",
    "#plt.plot(acc_t, color='r', label='Test')\n",
    "plt.grid()\n",
    "plt.title('ACURACY - All data' + name .format(PROPAG_STEPS, HIDDEN_LAYER, BATCH_SIZE, EPOCHS ))\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.rc('font', size=20)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=20)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=20)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=20)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=20)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=20)    # legend fontsize\n",
    "plt.rc('figure', titlesize=25)  # fontsize of the figure title\n",
    "\n",
    "plt.savefig(folder + 'Accuracy - d11 nz (8).png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(15, 10))\n",
    "#plt.plot(acc, color='b', label='Train')\n",
    "plt.plot(lss, color='r', label='Loss')\n",
    "#plt.plot(acc_t, color='r', label='Test')\n",
    "plt.grid()\n",
    "plt.title('Loss - All data' + name .format(PROPAG_STEPS, HIDDEN_LAYER, BATCH_SIZE, EPOCHS ))\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.rc('font', size=20)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=20)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=20)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=20)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=20)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=20)    # legend fontsize\n",
    "plt.rc('figure', titlesize=25)  # fontsize of the figure title\n",
    "\n",
    "plt.savefig(folder + 'Loss - d11 nz (8).png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Test\n",
    "\n",
    "epoch_loss_t = []\n",
    "loss_ls_t = []\n",
    "predict_t = []\n",
    "acc_t = []\n",
    "lss_t = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.eval()\n",
    "    acc_ep_t = []\n",
    "    loss_ep_t = []\n",
    "    for batch in TestLoader:\n",
    "        X, T, idx = batch\n",
    "        A = adj_matrices[idx]\n",
    "        D = dist_matrices[idx]\n",
    "        Y = model(X.cuda(), A.cuda()) \n",
    "        \n",
    "        loss_t = criterion_2(Y, T.cuda())\n",
    "        \n",
    "        predictions_t = torch.exp(Y).argmax(-1)\n",
    "        aux_t = 0\n",
    "        for j in range(len(T)):\n",
    "            \n",
    "            if T[j].item() == predictions_t[j].item():\n",
    "                aux_t += 1\n",
    "        #print('Acc:', aux_t/len(T))\n",
    "        acc_ep_t.append(aux_t/len(T))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss_t.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss_t.append(loss_t.item())\n",
    "        loss_ls_t.append(loss_t.item())\n",
    "        \n",
    "        loss_ep_t.append(loss_t.item())\n",
    "\n",
    "        predict_t.append(torch.exp(Y).argmax(-1))\n",
    "    acc_t.append(np.array(acc_ep_t).mean())\n",
    "    lss_t.append(np.array(loss_ep_t).mean())\n",
    "    print('EPOCH: ', epoch)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMN0AXcDZmSLprV3vhtEDkV",
   "collapsed_sections": [
    "lZ1VXGotIylR",
    "t9kxMPHlcFEt",
    "HL-h1dCcw9ET",
    "sUeYz-CEHP6J"
   ],
   "include_colab_link": true,
   "name": "ggnn_fault_loc.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
